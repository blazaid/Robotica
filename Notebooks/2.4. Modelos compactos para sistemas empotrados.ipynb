{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div><img width=\"120px\" style=\"float: right; width: 120px; vertical-align:middle\" src=\"https://www.upm.es/sfs/Rectorado/Gabinete%20del%20Rector/Logos/EU_Informatica/ETSI%20SIST_INFORM_COLOR.png\" alt=\"ETSISI logo\" />\n",
    "\n",
    "\n",
    "# Modelos compactos para sistemas empotrados<a id=\"top\"></a>\n",
    "\n",
    "<i><small>Autores: Alberto Díaz Álvarez y Guillermo Iglesias Hernández<br>Última actualización: 2023-10-09</small></i></div>\n",
    "                                                  \n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducción"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El aprendizaje automático (ML, del inglés _Machine Learning_) ha encontrado aplicaciones en una amplia variedad de campos, revolucionando la forma en que se resuelven los problemas y se toman decisiones. Sin embargo, la mayoría de las aplicaciones de ML tradicionales dependen de grandes infraestructuras (local o en la nube) para el entrenamiento y la inferencia. En contraste, TinyML se refiere a la práctica de ejecutar modelos de aprendizaje automático en dispositivos de borde (<i>edge computing</i>) con recursos limitados, como microcontroladores.\n",
    "\n",
    "La ventaja de TinyML radica en su capacidad para llevar la inteligencia de la máquina directamente a los dispositivos de borde, permitiendo la inferencia en tiempo real con baja latencia y preservación de la privacidad, ya que los datos no necesitan ser transmitidos a un servidor central para su procesamiento. Además, TinyML puede operar en condiciones de conectividad limitada o nula, lo cual es crucial en muchos escenarios del mundo real."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objetivos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El propósito de este notebook es proporcionar una comprensión práctica del flujo de trabajo involucrado en un proyecto TinyML. Los objetivos específicos incluyen:\n",
    "\n",
    "1. **Entendimiento del Proceso de Creación del Modelo:** Lo cual ya hemos explorado en los anteriores <i>notebooks</i>,\n",
    "2. **Conversión del Modelo a TensorFlow Lite:** Convertir el modelo entrenado a un formato que pueda ser ejecutado en microcontroladores usando TensorFlow Lite.\n",
    "3. **Cuantización del Modelo:**, Explorar la cuantización del modelo para reducir el tamaño del modelo, lo cual es vital para la implementación en determinados dispositivos con recursos limitados.\n",
    "\n",
    "Al final de este notebook, deberías tener una comprensión clara de cómo se puede desarrollar un modelo de aprendizaje automático, convertirlo para su uso en microcontroladores, y optimizar su tamaño a través de la cuantización, facilitando así su implementación en dispositivos de borde."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bibliotecas y configuración"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comenzaremos instalando las bibliotecas necesarias. Esto sólo es necesario en el caso de que no tengamos el entorno ya creado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in /home/blazaid/.cache/pypoetry/virtualenvs/notebooks-WUQkwkS2-py3.10/lib/python3.10/site-packages (3.8.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/blazaid/.cache/pypoetry/virtualenvs/notebooks-WUQkwkS2-py3.10/lib/python3.10/site-packages (from matplotlib) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/blazaid/.cache/pypoetry/virtualenvs/notebooks-WUQkwkS2-py3.10/lib/python3.10/site-packages (from matplotlib) (0.12.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/blazaid/.cache/pypoetry/virtualenvs/notebooks-WUQkwkS2-py3.10/lib/python3.10/site-packages (from matplotlib) (4.43.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/blazaid/.cache/pypoetry/virtualenvs/notebooks-WUQkwkS2-py3.10/lib/python3.10/site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: numpy<2,>=1.21 in /home/blazaid/.cache/pypoetry/virtualenvs/notebooks-WUQkwkS2-py3.10/lib/python3.10/site-packages (from matplotlib) (1.26.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/blazaid/.cache/pypoetry/virtualenvs/notebooks-WUQkwkS2-py3.10/lib/python3.10/site-packages (from matplotlib) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/blazaid/.cache/pypoetry/virtualenvs/notebooks-WUQkwkS2-py3.10/lib/python3.10/site-packages (from matplotlib) (10.0.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/blazaid/.cache/pypoetry/virtualenvs/notebooks-WUQkwkS2-py3.10/lib/python3.10/site-packages (from matplotlib) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/blazaid/.cache/pypoetry/virtualenvs/notebooks-WUQkwkS2-py3.10/lib/python3.10/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/blazaid/.cache/pypoetry/virtualenvs/notebooks-WUQkwkS2-py3.10/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: numpy in /home/blazaid/.cache/pypoetry/virtualenvs/notebooks-WUQkwkS2-py3.10/lib/python3.10/site-packages (1.26.0)\n",
      "Requirement already satisfied: pandas in /home/blazaid/.cache/pypoetry/virtualenvs/notebooks-WUQkwkS2-py3.10/lib/python3.10/site-packages (2.1.1)\n",
      "Requirement already satisfied: numpy>=1.22.4 in /home/blazaid/.cache/pypoetry/virtualenvs/notebooks-WUQkwkS2-py3.10/lib/python3.10/site-packages (from pandas) (1.26.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/blazaid/.cache/pypoetry/virtualenvs/notebooks-WUQkwkS2-py3.10/lib/python3.10/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/blazaid/.cache/pypoetry/virtualenvs/notebooks-WUQkwkS2-py3.10/lib/python3.10/site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/blazaid/.cache/pypoetry/virtualenvs/notebooks-WUQkwkS2-py3.10/lib/python3.10/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /home/blazaid/.cache/pypoetry/virtualenvs/notebooks-WUQkwkS2-py3.10/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: tensorflow in /home/blazaid/.cache/pypoetry/virtualenvs/notebooks-WUQkwkS2-py3.10/lib/python3.10/site-packages (2.14.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /home/blazaid/.cache/pypoetry/virtualenvs/notebooks-WUQkwkS2-py3.10/lib/python3.10/site-packages (from tensorflow) (2.0.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/blazaid/.cache/pypoetry/virtualenvs/notebooks-WUQkwkS2-py3.10/lib/python3.10/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /home/blazaid/.cache/pypoetry/virtualenvs/notebooks-WUQkwkS2-py3.10/lib/python3.10/site-packages (from tensorflow) (23.5.26)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /home/blazaid/.cache/pypoetry/virtualenvs/notebooks-WUQkwkS2-py3.10/lib/python3.10/site-packages (from tensorflow) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/blazaid/.cache/pypoetry/virtualenvs/notebooks-WUQkwkS2-py3.10/lib/python3.10/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /home/blazaid/.cache/pypoetry/virtualenvs/notebooks-WUQkwkS2-py3.10/lib/python3.10/site-packages (from tensorflow) (3.9.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /home/blazaid/.cache/pypoetry/virtualenvs/notebooks-WUQkwkS2-py3.10/lib/python3.10/site-packages (from tensorflow) (16.0.6)\n",
      "Requirement already satisfied: ml-dtypes==0.2.0 in /home/blazaid/.cache/pypoetry/virtualenvs/notebooks-WUQkwkS2-py3.10/lib/python3.10/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: numpy>=1.23.5 in /home/blazaid/.cache/pypoetry/virtualenvs/notebooks-WUQkwkS2-py3.10/lib/python3.10/site-packages (from tensorflow) (1.26.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/blazaid/.cache/pypoetry/virtualenvs/notebooks-WUQkwkS2-py3.10/lib/python3.10/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in /home/blazaid/.cache/pypoetry/virtualenvs/notebooks-WUQkwkS2-py3.10/lib/python3.10/site-packages (from tensorflow) (23.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /home/blazaid/.cache/pypoetry/virtualenvs/notebooks-WUQkwkS2-py3.10/lib/python3.10/site-packages (from tensorflow) (4.24.3)\n",
      "Requirement already satisfied: setuptools in /home/blazaid/.cache/pypoetry/virtualenvs/notebooks-WUQkwkS2-py3.10/lib/python3.10/site-packages (from tensorflow) (68.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/blazaid/.cache/pypoetry/virtualenvs/notebooks-WUQkwkS2-py3.10/lib/python3.10/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/blazaid/.cache/pypoetry/virtualenvs/notebooks-WUQkwkS2-py3.10/lib/python3.10/site-packages (from tensorflow) (2.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/blazaid/.cache/pypoetry/virtualenvs/notebooks-WUQkwkS2-py3.10/lib/python3.10/site-packages (from tensorflow) (4.8.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /home/blazaid/.cache/pypoetry/virtualenvs/notebooks-WUQkwkS2-py3.10/lib/python3.10/site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/blazaid/.cache/pypoetry/virtualenvs/notebooks-WUQkwkS2-py3.10/lib/python3.10/site-packages (from tensorflow) (0.34.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/blazaid/.cache/pypoetry/virtualenvs/notebooks-WUQkwkS2-py3.10/lib/python3.10/site-packages (from tensorflow) (1.59.0)\n",
      "Requirement already satisfied: tensorboard<2.15,>=2.14 in /home/blazaid/.cache/pypoetry/virtualenvs/notebooks-WUQkwkS2-py3.10/lib/python3.10/site-packages (from tensorflow) (2.14.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.15,>=2.14.0 in /home/blazaid/.cache/pypoetry/virtualenvs/notebooks-WUQkwkS2-py3.10/lib/python3.10/site-packages (from tensorflow) (2.14.0)\n",
      "Requirement already satisfied: keras<2.15,>=2.14.0 in /home/blazaid/.cache/pypoetry/virtualenvs/notebooks-WUQkwkS2-py3.10/lib/python3.10/site-packages (from tensorflow) (2.14.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /home/blazaid/.cache/pypoetry/virtualenvs/notebooks-WUQkwkS2-py3.10/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.41.2)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/blazaid/.cache/pypoetry/virtualenvs/notebooks-WUQkwkS2-py3.10/lib/python3.10/site-packages (from tensorboard<2.15,>=2.14->tensorflow) (2.23.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /home/blazaid/.cache/pypoetry/virtualenvs/notebooks-WUQkwkS2-py3.10/lib/python3.10/site-packages (from tensorboard<2.15,>=2.14->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/blazaid/.cache/pypoetry/virtualenvs/notebooks-WUQkwkS2-py3.10/lib/python3.10/site-packages (from tensorboard<2.15,>=2.14->tensorflow) (3.4.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/blazaid/.cache/pypoetry/virtualenvs/notebooks-WUQkwkS2-py3.10/lib/python3.10/site-packages (from tensorboard<2.15,>=2.14->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/blazaid/.cache/pypoetry/virtualenvs/notebooks-WUQkwkS2-py3.10/lib/python3.10/site-packages (from tensorboard<2.15,>=2.14->tensorflow) (0.7.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/blazaid/.cache/pypoetry/virtualenvs/notebooks-WUQkwkS2-py3.10/lib/python3.10/site-packages (from tensorboard<2.15,>=2.14->tensorflow) (2.3.7)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/blazaid/.cache/pypoetry/virtualenvs/notebooks-WUQkwkS2-py3.10/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (5.3.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/blazaid/.cache/pypoetry/virtualenvs/notebooks-WUQkwkS2-py3.10/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/blazaid/.cache/pypoetry/virtualenvs/notebooks-WUQkwkS2-py3.10/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/blazaid/.cache/pypoetry/virtualenvs/notebooks-WUQkwkS2-py3.10/lib/python3.10/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/blazaid/.cache/pypoetry/virtualenvs/notebooks-WUQkwkS2-py3.10/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/blazaid/.cache/pypoetry/virtualenvs/notebooks-WUQkwkS2-py3.10/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/blazaid/.cache/pypoetry/virtualenvs/notebooks-WUQkwkS2-py3.10/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow) (2.0.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/blazaid/.cache/pypoetry/virtualenvs/notebooks-WUQkwkS2-py3.10/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/blazaid/.cache/pypoetry/virtualenvs/notebooks-WUQkwkS2-py3.10/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.15,>=2.14->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /home/blazaid/.cache/pypoetry/virtualenvs/notebooks-WUQkwkS2-py3.10/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (0.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/blazaid/.cache/pypoetry/virtualenvs/notebooks-WUQkwkS2-py3.10/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow) (3.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib\n",
    "!pip install numpy\n",
    "!pip install pandas\n",
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación importaremos las bibliotecas que se utilizarán a lo largo del notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-09 01:41:53.989198: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-10-09 01:41:53.989224: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-10-09 01:41:53.989239: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-10-09 01:41:53.993466: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-09 01:41:54.509909: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import zipfile\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Forzamos algunos parámetros de configuración"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "plt.rcParams.update({'figure.figsize': (20, 6),'figure.dpi': 64})\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"  # Usar CPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qHKBJBaXrwxO"
   },
   "source": [
    "## Preparación del conjunto de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya conocemos el conjunto de datos MNIST. Ahora procederemos a:\n",
    "\n",
    "1. Cargar conjuntos de datos de entrenamiento y test,\n",
    "2. Normalizar valores de entrada al intervalo $[0, 1]$,\n",
    "3. Añadir una nueva dimensión que represente el único canal de color porque vamos a usar una red convolucional.\n",
    "\n",
    "No transformaremos las etiquetas del dataset ya que usaremos la versión _sparse_ del _loss_ de la entropía cruzada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensiones entrenamiento: (60000, 28, 28, 1) input, (60000,) output\n",
      "Dimensiones test:          (10000, 28, 28, 1) input, (10000,) output\n"
     ]
    }
   ],
   "source": [
    "# Descarga de datos\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "# Normalización\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "# Nueva dimensión\n",
    "x_train, x_test = x_train[..., np.newaxis], x_test[..., np.newaxis]\n",
    "\n",
    "print(f'Dimensiones entrenamiento: {x_train.shape} input, {y_train.shape} output')\n",
    "print(f'Dimensiones test:          {x_test.shape} input, {y_test.shape} output')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo de predicción"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZN0Oe5S-kulZ"
   },
   "source": [
    "Crearemos una red de convolución normal similar a la del anterior ejemplo, usando para ellos capas de convolución, _pooling_, _flatten_ y densas. Aprovecharemos la función `create_model` para devolver el modelo ya compilado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "JA0gzRxikDeU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 24, 24, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 12, 12, 32)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 4608)              0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 4608)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                46090     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 55658 (217.41 KB)\n",
      "Trainable params: 55658 (217.41 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-09 01:41:55.085720: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:268] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2023-10-09 01:41:55.085744: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:168] retrieving CUDA diagnostic information for host: margaret\n",
      "2023-10-09 01:41:55.085749: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:175] hostname: margaret\n",
      "2023-10-09 01:41:55.085807: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:199] libcuda reported version is: 525.125.6\n",
      "2023-10-09 01:41:55.085819: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:203] kernel reported version is: 525.125.6\n",
      "2023-10-09 01:41:55.085823: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:309] kernel version seems to match DSO: 525.125.6\n"
     ]
    }
   ],
   "source": [
    "def create_model():\n",
    "    # Creación del grafo que representa a la red\n",
    "    input = tf.keras.Input(shape=(28, 28, 1))\n",
    "    output = tf.keras.layers.Conv2D(32, (3, 3), activation='relu')(input)\n",
    "    output = tf.keras.layers.Conv2D(32, (3, 3), activation='relu')(output)\n",
    "    output = tf.keras.layers.MaxPooling2D((2, 2))(output)\n",
    "    output = tf.keras.layers.Flatten()(output)\n",
    "    output = tf.keras.layers.Dropout(0.5)(output)\n",
    "    output = tf.keras.layers.Dense(10, activation='softmax')(output)\n",
    "    # Modelo que especifica qué nodos del grafo son los de entrada y de salida\n",
    "    model = tf.keras.Model(input, output)\n",
    "    # Compilación del modelo\n",
    "    model.compile(\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "        optimizer=tf.keras.optimizers.Adam(),\n",
    "        metrics=[tf.keras.metrics.SparseCategoricalAccuracy()]\n",
    "    )\n",
    "    \n",
    "    return model \n",
    "\n",
    "model = create_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t4LUTAfUsN20"
   },
   "source": [
    "Ahora entrenaremos el modelo durante 10 epochs para que esté ajustado al problema. Esta vez usaremos un split del conjunto de validación un poco más pequeño y un tamaño de batch más grande."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1688/1688 [==============================] - 16s 9ms/step - loss: 0.1965 - sparse_categorical_accuracy: 0.9399 - val_loss: 0.0556 - val_sparse_categorical_accuracy: 0.9852\n",
      "Epoch 2/10\n",
      "1688/1688 [==============================] - 15s 9ms/step - loss: 0.0829 - sparse_categorical_accuracy: 0.9744 - val_loss: 0.0461 - val_sparse_categorical_accuracy: 0.9875\n",
      "Epoch 3/10\n",
      "1688/1688 [==============================] - 16s 9ms/step - loss: 0.0646 - sparse_categorical_accuracy: 0.9799 - val_loss: 0.0426 - val_sparse_categorical_accuracy: 0.9872\n",
      "Epoch 4/10\n",
      "1688/1688 [==============================] - 16s 9ms/step - loss: 0.0550 - sparse_categorical_accuracy: 0.9824 - val_loss: 0.0430 - val_sparse_categorical_accuracy: 0.9890\n",
      "Epoch 5/10\n",
      "1688/1688 [==============================] - 16s 9ms/step - loss: 0.0464 - sparse_categorical_accuracy: 0.9851 - val_loss: 0.0429 - val_sparse_categorical_accuracy: 0.9895\n",
      "Epoch 6/10\n",
      "1688/1688 [==============================] - 16s 10ms/step - loss: 0.0438 - sparse_categorical_accuracy: 0.9862 - val_loss: 0.0426 - val_sparse_categorical_accuracy: 0.9888\n",
      "Epoch 7/10\n",
      "1688/1688 [==============================] - 16s 9ms/step - loss: 0.0401 - sparse_categorical_accuracy: 0.9869 - val_loss: 0.0326 - val_sparse_categorical_accuracy: 0.9903\n",
      "Epoch 8/10\n",
      "1688/1688 [==============================] - 16s 9ms/step - loss: 0.0371 - sparse_categorical_accuracy: 0.9876 - val_loss: 0.0340 - val_sparse_categorical_accuracy: 0.9913\n",
      "Epoch 9/10\n",
      "1688/1688 [==============================] - 16s 9ms/step - loss: 0.0335 - sparse_categorical_accuracy: 0.9892 - val_loss: 0.0345 - val_sparse_categorical_accuracy: 0.9908\n",
      "Epoch 10/10\n",
      "1688/1688 [==============================] - 16s 9ms/step - loss: 0.0330 - sparse_categorical_accuracy: 0.9891 - val_loss: 0.0358 - val_sparse_categorical_accuracy: 0.9907\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, epochs=10, batch_size=32, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S65WKzIUlIDZ"
   },
   "source": [
    "Veamos cómo ha progresado el entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 41588,
     "status": "ok",
     "timestamp": 1666289947488,
     "user": {
      "displayName": "Punto",
      "userId": "10186899819214684786"
     },
     "user_tz": -120
    },
    "id": "qMdV9mRVlFTi",
    "outputId": "1ad894a6-4af1-4d94-e19b-6dfcc7e44d11"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1280x384 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(history.history).plot()\n",
    "plt.xlabel('Epoch num.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Independientemente de lo bueno o malo que parezca, vamos a seguir con este modelo.\n",
    "\n",
    "Antes de nada salvaremos el modelo a fichero para realizar comparativas; para ello usaremos el método `save` del propio modelo. Antiguamente el formato de salvado era el HDF5. De hecho se puede seguir usando, aunque se considera _legacy_ y en algún momento desaparecerá de la biblioteca.\n",
    "\n",
    "El formato actual, `.keras`, es un fichero zip que contiene la arquitectura (fichero `config.json`), los pesos (fichero `model.weights.h5`) y demás metainformación (fichero `metadata.json`) del modelo. Esto nos permite, entre otros, salvar y cargar el modelo en estadios intermedios de un entrenamiento, por ejemplo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_MODEL = 'base_model.keras'\n",
    "\n",
    "model.save(BASE_MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos el contenido del fichero y cuánto ocupa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño de \"base_model.keras\": 686.827 KiB\n",
      "Contenidos del fichero:  ['metadata.json', 'config.json', 'model.weights.h5']\n"
     ]
    }
   ],
   "source": [
    "print(f'Tamaño de \"{BASE_MODEL}\": {os.path.getsize(BASE_MODEL) / 1024:.6} KiB')\n",
    "zip = zipfile.ZipFile(BASE_MODEL)\n",
    "print(f'Contenidos del fichero:  {zip.namelist()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversión a TFLite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El primer paso para convertir un modelo entrenado de TensorFlow (vale, en keras, pero usando como _backend_ TensorFlow) es la creación del objeto convertidor de la clase `TFLiteConverter`. Este objeto será el responsable de llevar a cabo la conversión del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora podemos proceder a converir el modelo a formato TFLite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpz9bkcv4r/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpz9bkcv4r/assets\n",
      "2023-10-09 01:44:33.749145: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2023-10-09 01:44:33.749161: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2023-10-09 01:44:33.749348: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmpz9bkcv4r\n",
      "2023-10-09 01:44:33.750040: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2023-10-09 01:44:33.750047: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /tmp/tmpz9bkcv4r\n",
      "2023-10-09 01:44:33.751509: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:382] MLIR V1 optimization pass is not enabled\n",
      "2023-10-09 01:44:33.752003: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2023-10-09 01:44:33.774031: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /tmp/tmpz9bkcv4r\n",
      "2023-10-09 01:44:33.780372: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 31025 microseconds.\n",
      "2023-10-09 01:44:33.789540: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n"
     ]
    }
   ],
   "source": [
    "tflite_model = converter.convert()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este paso, ejecutamos la conversión del modelo utilizando el método `convert` del objeto convertidor. Esto genera un modelo en formato TFLite que es adecuado para ejecutarse en dispositivos como microcontroladores.\n",
    "\n",
    "Este objeto se puede salvar a fichero trabajando como con cualquier objeto binario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "TFLITE_MODEL = 'tfl_model.tflite'\n",
    "\n",
    "with open(TFLITE_MODEL, 'wb') as f:\n",
    "    f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos la diferencia en tamañode ambos ficheros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base_model.keras: 686.827 KiB\n",
      "tfl_model.tflite: 220.055 KiB\n"
     ]
    }
   ],
   "source": [
    "for file in (BASE_MODEL, TFLITE_MODEL):\n",
    "    print(f'{file}: {os.path.getsize(file) / 1024:.6} KiB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bueno, más de un $50\\%$ de reducción, bastante bien."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cuantización del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La cuantización es un proceso que puede reducir significativamente tanto el tamaño del modelo como el tiempo de ejecución, con una pequeña pérdida en la precisión. Esto es especialmente útil en el contexto de TinyML, donde los recursos son limitados.\n",
    "\n",
    "Existen varias opciones de cuantización. Aquí nos centraremos en dos de tipo **post-entrenamiento** ofrecidas por TFLite. La **cuantización consciente del entrenamiento** o QAT (del inglés _Quantization Aware Training_) se basa en simular la cuantización de los pesos y activaciones durante el entrenamiento; de esta manera el modelo aprende a compensar la pérdida de precisión que ocurre durante la cuantización, resultando en un modelo cuantizado con una precisión mucho más cercana al modelo original de punto flotante. Sin embargo este proceso es más complejo y va más allá del alcance de este _notebook_.\n",
    "\n",
    "La cuantización **post-entrenamiento** es un proceso que convierte los los valores de punto flotante a valores enteros después del entrenamiento. Esto puede reducir el tamaño del modelo y mejorar el rendimiento sin necesidad de reentrenar el modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cuantización estática\n",
    "\n",
    "Convierte los pesos del modelo y de las funciones de activación de punto flotante a valores enteros después del entrenamiento. Esto generalmente reduce el tamaño del modelo y mejora su rendimiento, aunque a costa de una pérdida de precisión.\n",
    "\n",
    "Se configura a través de un parámetro de optimización (`Optimize.DEFAULT`) del converter. Crearemos un nuevo fichero con el modelo comprimido con esta configuración."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmphlv9p9s9/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmphlv9p9s9/assets\n",
      "2023-10-09 01:44:34.217602: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2023-10-09 01:44:34.217617: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2023-10-09 01:44:34.217729: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmphlv9p9s9\n",
      "2023-10-09 01:44:34.218416: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2023-10-09 01:44:34.218424: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /tmp/tmphlv9p9s9\n",
      "2023-10-09 01:44:34.220086: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2023-10-09 01:44:34.242013: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /tmp/tmphlv9p9s9\n",
      "2023-10-09 01:44:34.248475: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 30747 microseconds.\n"
     ]
    }
   ],
   "source": [
    "TFLITE_STATIC_QUANT_MODEL = 'tsq_model.tflite'\n",
    "\n",
    "# Creación del convertidor y configuración\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "\n",
    "# Convertimos el modelo\n",
    "tflite_static_quant_model = converter.convert()\n",
    "\n",
    "# Salvado a fichero\n",
    "with open(TFLITE_STATIC_QUANT_MODEL, 'wb') as f:\n",
    "    f.write(tflite_static_quant_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cuantización dinámica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convierte los pesos a enteros pero mantiene las activaciones en punto flotante. Esto es útil para ciertos modelos y puede proporcionar un equilibrio entre tamaño, rendimiento y precisión.\n",
    "\n",
    "Al igual que con la estática, la dinámica se configura a través de un parámetro de optimización (`Optimize.OPTIMIZE_FOR_LATENCY`) del converter. Crearemos también un fichero con esta configuración."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Optimization option OPTIMIZE_FOR_LATENCY is deprecated, please use optimizations=[Optimize.DEFAULT] instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmprzm2yfe2/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmprzm2yfe2/assets\n",
      "WARNING:absl:Optimization option OPTIMIZE_FOR_LATENCY is deprecated, please use optimizations=[Optimize.DEFAULT] instead.\n",
      "WARNING:absl:Optimization option OPTIMIZE_FOR_LATENCY is deprecated, please use optimizations=[Optimize.DEFAULT] instead.\n",
      "2023-10-09 01:44:34.663672: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2023-10-09 01:44:34.663687: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2023-10-09 01:44:34.663799: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmprzm2yfe2\n",
      "2023-10-09 01:44:34.664481: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2023-10-09 01:44:34.664488: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /tmp/tmprzm2yfe2\n",
      "2023-10-09 01:44:34.666158: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2023-10-09 01:44:34.686914: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /tmp/tmprzm2yfe2\n",
      "2023-10-09 01:44:34.693031: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 29231 microseconds.\n"
     ]
    }
   ],
   "source": [
    "TFLITE_DYNAMIC_QUANT_MODEL = 'tdq_model.tflite'\n",
    "\n",
    "# Creación del convertidor y configuración\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_LATENCY]\n",
    "\n",
    "# Convertimos el modelo\n",
    "tflite_dynamic_quant_model = converter.convert()\n",
    "\n",
    "# Salvado a fichero\n",
    "with open(TFLITE_DYNAMIC_QUANT_MODEL, 'wb') as f:\n",
    "    f.write(tflite_dynamic_quant_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparación de espacio en disco\n",
    "\n",
    "A continuación se muestra el tamaño ocupado por cada uno de los diferentes ficheros de modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base_model.keras: 686.827 KiB\n",
      "tfl_model.tflite: 220.055 KiB\n",
      "tsq_model.tflite: 58.5391 KiB\n",
      "tdq_model.tflite: 58.5391 KiB\n"
     ]
    }
   ],
   "source": [
    "for file in (\n",
    "    BASE_MODEL,\n",
    "    TFLITE_MODEL,\n",
    "    TFLITE_STATIC_QUANT_MODEL,\n",
    "    TFLITE_DYNAMIC_QUANT_MODEL,\n",
    "): \n",
    "    print(f'{file}: {os.path.getsize(file) / 1024:.6} KiB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Curiosamente el modelo es el mismo (o al menos equivalente en tamaño) en las dos versiones cuantizadas. Eso sí, ocupan $10$ veces menos que el modelo original, lo cual es un gran logro."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusiones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hemos navegado por los distintos pasos involucrados en la preparación y optimización de un modelo de aprendizaje automático para dispositivos de borde bajo el paradigma de TinyML. Los puntos clave obtenidos son los siguientes:\n",
    "\n",
    "- Un buen dataset y una buena arquitectura son cruciales para el éxito del proyecto. Un modelo bien entrenado y validado es el punto de partida para cualquier proyecto TinyML.\n",
    "- La conversión del modelo a TensorFlow Lite es un paso esencial para preparar el modelo para su ejecución en microcontroladores. Es de fácil implementación haciendo uso de convertidores, los cuales nos transforman un modelo de TensorFlow a un formato compatible con dispositivos _de frontera_.\n",
    "- La cuantización es una técnica muy valiosa para reducir el tamaño del modelo y acelerar la inferencia, lo que es crucial para el desempeño en dispositivos con recursos limitados. Exploramos la cuantización post-entrenamiento, que es una forma eficaz y sencilla de cuantizar un modelo sin la necesidad de reentrenamiento.\n",
    "\n",
    "Este proyecto proporciona una base sólida para explorar más a fondo cómo TinyML puede desbloquear nuevas capacidades en dispositivos de _edge computing_ y cómo podemos continuar optimizando y desplegando modelos de aprendizaje automático en hardware con recursos limitados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UaneBW10p6JH"
   },
   "source": [
    "***\n",
    "\n",
    "<div><img style=\"float: right; width: 120px; vertical-align:top\" src=\"https://mirrors.creativecommons.org/presskit/buttons/88x31/png/by-nc-sa.png\" alt=\"Creative Commons by-nc-sa logo\" />\n",
    "\n",
    "[Volver al inicio](#top)\n",
    "\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [
    {
     "file_id": "/v2/external/notebooks/gpu.ipynb",
     "timestamp": 1611939535453
    }
   ]
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
