---
marp : true
title : Deep learning en visión
author :
  - Alberto Díaz Álvarez <alberto.diaz@upm.es>
  - Guillermo Iglesias Hernández <guillermo.iglesias@upm.es>
paginate : true
theme : etsisi
description : >
  El deep learning como herramienta para la visión por computador
keywords: >
  Robótica, Percepción, Visión
math: mathjax
---

<!-- _class: titlepage -->

# Deep learning en visión

## Robótica

### Guillermo Iglesias Hernández y Alberto Díaz Álvarez

#### Departamento de Sistemas Informáticos - Universidad Politécnica de Madrid

##### 5 de octubre de 2023

[![height:30](https://img.shields.io/badge/License-CC%20BY--NC--SA%204.0-informational.svg)](https://creativecommons.org/licenses/by-nc-sa/4.0/)

---

# Conceptos básicos de redes de neuronas<!-- _class: section -->

---

# Neurona biológica vs. artificial

Sistema matemático capaz de realizar predicciones a partir de datos de entrada

- Propuesta por McCulloch y Pitts en 1943
- Basada en _imitar_ el comportamiento de una neurona biológica
- Toma ciertos _estímulos_ de entrada, los procesa y genera una nueva salida

<div class="columns">
<div class="column">

## Neurona biológica

- Estímulos $\rightarrow$ _impulsos nerviosos_

<center>
<img src="https://upload.wikimedia.org/wikipedia/commons/4/44/Neuron3.png" alt="Ilustración de una neurona biológica" style="height:150">
<figcaption align="center">

**Fig.1** - Neurona biológica. Fuente: [Wikipedia](https://commons.wikimedia.org/wiki/File:Neuron3.png).

</figcaption>
</center>
</div>
<div class="column">

## Neurona artificial

- Estímulos $\rightarrow$ _cálculos matemáticos_

<center>
<img src="https://upload.wikimedia.org/wikipedia/commons/5/53/Artificial_Neuron.svg" alt="Diagrama de neurona artificial" style="height:150">
<figcaption align="center">

**Fig.2** - Neurona artificial. Fuente: [Wikipedia](https://commons.wikimedia.org/wiki/File:Artificial_Neuron.svg).

</figcaption>
</center>
</div>
</div>

---

# Neurona artificial

Realiza cálculos matemáticos para transformar ciertos valores numéricos

<center>
<img src="https://www.electronicshub.org/wp-content/uploads/2019/05/Artificial-Neural-Networks-ANN-Processing-Units.jpg" alt="Componentes de una neurona" style="height: 200px">
<figcaption align="center">

**Fig.3** - Neurona artificial. Fuente: [ElectronicsHub](https://www.electronicshub.org/artificial-neural-networks-ann/).

</figcaption>
</center>

Para ello, existen diversos _elementos_ dentro de una neurona artificial:

- **Entradas** ($x_i$): Los valores numéricos de entrada
- **Salida** ($y$): El valor de salida de la neurona
- **Pesos** ($w_i$): Parámetros capaces de cambiar, suponen el aprendizaje de la neurona
- **Bias** ($b$): Peso cuya entrada _siempre_ es $1$ y que desplaza la función de activación
- **Función de activación**: $a$: Participa en el cálculo de la salida de la neurona

---

# Entrenamiento

<div class="columns-third">
<div class="column">

En un esquema supervisado, podemos dividir el entrenamiento de una red neuronal en tres fases:

- **Inferencia**: Calculamos la salida de la red en función de las entradas y los pesos
- **Calculo del error**: Dadas las salida de la red y el resultado que queremos obtener calculamos el error obtenido
- **Ajuste de pesos**: Con dicho error se reajustan los parámetros de la red

</div>
<div class="column">

<center>
<img src="https://imgs.xkcd.com/comics/trained_a_neural_net.png" alt="Cómic de aprendizaje automático">
<figcaption align="center">

**Fig.4** - Neurona artificial. Fuente: [XKCD](https://xkcd.com/2173/).

</figcaption>
</center>

</div>

---

# Algoritmo de propagación

La fase de \alert{predicción} de una red neuronal se realiza a través del algoritmo de \alert{propagación}.

Este se encarga de procesar la \alert{entrada} y generar la \alert{salida} correspondiente.

Para ello, la computación de cada \alert{neurona} es la siguiente:
\begin{itemize}
    \item Cada entrada $x_{i}$ es \alert{multiplicada} por el valor de su peso correspondiente $w_{i}$.
    \item La entrada de \textit{bias} \alert{siempre} es \say{1}, y se multiplica por su peso correspondiente (a veces indicado como $w_{0}$).
    \item Todas las \alert{entradas} de la neurona se combinan haciendo una \alert{suma} de todas ellas, de tal manera que se realiza una \alert{combinación lineal}.
    \item El resultado de la combinación lineal se pasa por una \alert{función no lineal} para generar la \alert{salida} de la neurona.
\end{itemize}

---

# Algoritmo de propagación

La ecuación que define este \alert{proceso} es la siguiente:
\setcounter{equation}{0}
\begin{equation}
    \Large f\left(\sum_{i=0}^{n} W_{i} X_{i}\right)
\end{equation}

\begin{figure}
\centering
    \includegraphics[width=0.6\textwidth]{figures/Tema 3/PropagationExample_1.png}
\end{figure}
\end{frame}

\begin{frame}{Algoritmo de propagación}
La ecuación que define este \alert{proceso} es la siguiente:
\setcounter{equation}{0}
\begin{equation}
    \Large f\left(\sum_{i=0}^{n} W_{i} X_{i}\right)
\end{equation}

\begin{figure}
\centering
    \includegraphics[width=0.6\textwidth]{figures/Tema 3/PropagationExample_2.png}
\end{figure}

---

# Algoritmo de propagación

La ecuación que define este \alert{proceso} es la siguiente:
\setcounter{equation}{0}
\begin{equation}
    \Large f\left(\sum_{i=0}^{n} W_{i} X_{i}\right)
\end{equation}

\begin{figure}
\centering
    \includegraphics[width=0.6\textwidth]{figures/Tema 3/PropagationExample_3.png}
\end{figure}

---

# Algoritmo de propagación

La ecuación que define este \alert{proceso} es la siguiente:
\setcounter{equation}{0}
\begin{equation}
    \Large f\left(\sum_{i=0}^{n} W_{i} X_{i}\right)
\end{equation}

\begin{figure}
\centering
    \includegraphics[width=0.6\textwidth]{figures/Tema 3/PropagationExample_4.png}
\end{figure}

---

# Algoritmo de propagación

La ecuación que define este \alert{proceso} es la siguiente:
\setcounter{equation}{0}
\begin{equation}
    \Large f\left(\sum_{i=0}^{n} W_{i} X_{i}\right)
\end{equation}

\begin{figure}
\centering
    \includegraphics[width=0.8\textwidth]{figures/Tema 3/PropagationExample_5.png}
\end{figure}

---

# Estructura de capas

Una red de neuronas \say{estándar} se organiza por \alert{capas}, las cuales se componen por varias \alert{neuronas}.

Cada \alert{capa de neuronas} se conecta con la siguiente y recibe \alert{datos} de la anterior. De esta manera se produce el \alert{flujo de datos} a lo largo de la red.

\begin{figure}
\centering
    \includegraphics[width=0.8\textwidth]{figures/Tema 3/LayerStructure.png}
\end{figure}

---

# ¿Por qué introducir más capas?

Está matemáticamente \alert{demostrado} que sin función de activación las redes de neuronas sólo son capaces de resolver problemas \alert{linealmente separables}.

Esto es fácilmente demostrable, ya la computación de cada neurona corresponde con la ecuación de \alert{una recta}, y su combinación también.

\begin{figure}
\centering
    \includegraphics[width=0.5\textwidth]{figures/Tema 1/Separabilidad_Lineal.png}
\end{figure}

Por otra parte, K. Hornik, M. Stinchcombe, y H. White demostraron el 1985 que con \alert{una única capa oculta} las redes neuronales artificiales se convierten en aproximadores universales \cite{hornik1989multilayer}

---

# Funciones de activación

Las \alert{funciones de activación} de cada neurona pueden variar, entre las más populares se encuentran:

\begin{figure}
\centering
    \includegraphics[width=\textwidth]{figures/Tema 3/Activations.png}
    \caption{\cite{Activations}}
\end{figure}

---

# Algoritmo de retropropagación

El algoritmo de \alert{retropropagación} o \alert{backpropagation} es el encargado de \alert{adaptar} la red de neuronas a su cometido específico.

Se basa en actualizar los \alert{pesos} de la red dependiendo del \alert{error} que esta haya tenido a la hora de predecir una \alert{salida} en concreto.

Con backpropagation obtendremos los \alert{gradientes (derivadas)} de la función de pérdida
para cada \alert{peso} de cada \alert{capa oculta}.

\begin{equation}
    \bigtriangleup w_i = w_i - \alpha \cdot (Error)
\end{equation}

donde $\alpha$ es el \alert{learning rate}, que define la \alert{magnitud} con la que la red realiza la \alert{actualización} de sus pesos.

---

# Funciones de pérdida

Existen múltiples métodos para calcular la \alert{distancia} de la \alert{predicción $\hat{y}$} con respecto de la \alert{salida deseada $y$}. Es decir, múltiples funciones de pérdida que nos permiten calcular el error.

\begin{equation}
    \textbf{MAE} = \frac{1}{n} \sum{\left | y - \hat{y} \right |}
\end{equation}

\begin{equation}
    \textbf{MSE} = \frac{1}{n}\sum{(y - \hat{y})^2}
\end{equation}

\begin{equation}
    \textbf{Cross-Entropy} = - \sum{y \cdot  \log \hat{y}}
\end{equation}

---

# Entrenamiento de redes neuronales

Al realizar un entrenamiento con \alert{modelos de aprendizaje} se realiza una división del \alert{conjunto de datos} con el que se entrena. Este proceso ayuda a comprobar la \alert{fiabilidad} de la red.

\begin{figure}
\centering
    \includegraphics[width=0.6\textwidth]{figures/Tema 3/DatasetDivision.png}
\end{figure}

---

# Bias-variance tradeoff

Existen dos \alert{métricas} de alto nivel que evalúan el rendimiento de una red neuronal:
\begin{itemize}
    \item \alert{Bias}: Es el error del modelo ante el conjunto de datos de \alert{entrenamiento}.
    \item \alert{Variance}: Es el error del modelo ante el conjunto de datos de \alert{testeo} respecto los de entrenamiento. 
\end{itemize}

\begin{figure}
\centering
    \includegraphics[width=\textwidth]{figures/Tema 3/BiasVariance_1.jpg}
    \caption{\cite{BiasVariance_1}}
\end{figure}

---

# Bias-variance tradeoff

\centering
    \includegraphics[width=0.7\textwidth]{figures/Tema 3/BiasVariance.png}
    \caption{\cite{BiasVariance}}
\end{figure}

---

# ¿Cómo detectar alto bias o variance?

\begin{columns}[c]
\begin{column}{0.49\textwidth}
\Large \alert{Alto bias}
\end{column}

\begin{column}{0.49\textwidth}
\Large \alert{Alto variance}
\end{column}
\end{columns}

\begin{columns}[c]
\begin{column}{0.49\textwidth}
\begin{itemize}
    \item Underfitting.
    \item Sobre-simplificación del problema.
    \item Valores de pérdida demasiado altos.
    \item Falla al capturar la tendencia de los datos.
\end{itemize} 
\end{column}

\begin{column}{0.49\textwidth}
\begin{itemize}
    \item Overfitting.
    \item Dataset demasiado ruidoso.
    \item Demasiada complejidad.
\end{itemize} 
\end{column}
\end{columns}

---

# Esquema general de entrenamiento de redes neuronales

\begin{figure}
\centering
    \includegraphics[width=0.9\textwidth]{figures/Tema 3/NNTrainingScheme.png}
\end{figure}

---

# Problemas del gradiente

Los problemas \alert{derivados del gradiente} son comunes a todas las redes neuronales. Estos están \alert{directamente influenciados} por el número de capas de la red.

Se diferencian dos tipos:
\begin{itemize}
    \item Gradient explosion.
    \item Gradient vanishing.
\end{itemize}

Al realizarse la \alert{retropropagación} los \alert{valores de pérdida} pasan de unas capas a otras. En este algoritmo las derivadas de cada neurona pueden llegar a \alert{descontrolarse}.

\begin{equation}
    W_{x}^{\prime}=W_{x}-\mathrm{\alpha}\left(\frac{\partial \text {Loss}}{\partial W_{x}}\right)
\end{equation}

---

# Problemas del gradiente: Gradient explosion

\begin{figure}
    \centering
    \includegraphics[width=0.6\textwidth]{figures/Tema 3/GradientExplosion.png}
    \caption{\cite{GradienExplosion}}
\end{figure}

El \alert{gradient explosion}, también conocido como \alert{exploding gradients} sucede cuando la actualización de pesos toma valores \alert{muy elevados}.

Se identifica con valores de pérdidas de \alert{NaN o muy exageradas}

---

# Problemas del gradiente: Gradient Vanishing

\begin{figure}
    \centering
    \includegraphics[width=0.6\textwidth]{figures/Tema 3/GradientVanishing.png}
    \caption{\cite{GradienVanishing}}
\end{figure}

Cuando sucede \alert{gradient vanishing}, también llamado \alert{vanishing gradients}, la actualización de pesos se hace \alert{nula} por tener valores \alert{muy pequeños}.

Se identifica cuando la pérdida es \alert{constante en el tiempo}

---

# Origen de los problemas derivados del gradiente

La principal \alert{causa} de estos problemas es usar \alert{funciones de activación} cuya derivada \alert{satura a 0}.

\begin{figure}
    \centering
    \includegraphics[width=0.6\textwidth]{figures/Tema 3/GradientCause.png}
    \caption{\cite{GradienExplosion}}
\end{figure}

Sucede principalmente con las funciones \alert{tanh} y \alert{sigmoid}, por lo tanto se \alert{recomienda} el uso de ReLU para capas ocultas en una red.

---

# Playground}
\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{figures/Tema 3/Playground.png}
    \caption{\href{https://playground.tensorflow.org/}{Tensorflow playground}}
\end{figure}

---

# Perceptrón multicapa para procesar imágenes

---

# ¿Cómo procesar imágenes?

La idea más \alert{básica} para procesar imágenes con redes neuronales es  transformar la \alert{matriz numérica} de datos a un \alert{vector unidimensional}.

\begin{figure}
    \centering
    \includegraphics[width=0.7\textwidth]{figures/Tema 3/NNVideo.jpg}
    \caption{\href{https://www.youtube.com/watch?v=aircAruvnKk&t=218s}{Vídeo youtube}}
\end{figure}

---

# Capa de reshape

La capa de \alert{keras} llamada \say{\alert{reshape}} se encarga de realizar esa transformación de \alert{matriz} a \alert{vector}.

Sin embargo el principal \alert{inconveniente} al tratar las imágenes de esta manera es la \alert{pérdida total} de información espacial de la imagen

---

# Implementando un perceptrón multicapa

<center>
<img src="https://upload.wikimedia.org/wikipedia/commons/d/d0/Google_Colaboratory_SVG_Logo.svg" alt="Logotipo de Google Colab" style="height:250px">
<figcaption align="center">

</figcaption>
</center>

El siguiente notebook contiene un ejemplo de clasificador de imágenes usando un perceptrón multicapa como red neuronal

Ejercicio: [2.2. Clasificación de dígitos con un perceptrón multicapa.ipynb](https://githubtocolab.com/etsisi/Robotica/blob/main/Notebooks/2.2.%20Clasificación%20de%20dígitos%20con%20un%20perceptrón%20multicapa.ipynb)<sup>1</sup>

> <https://githubtocolab.com/etsisi/Robotica/blob/main/Notebooks/2.2.%20Clasificación%20de%20dígitos%20con%20un%20perceptrón%20multicapa.ipynb>

---

\title{Redes convolucionales}

\begin{document}
\maketitle

\section{Motivación}

\begin{frame}{Problemas del perceptrón}
Como anteriormente se ha visto, una arquitectura de \alert{perceptrón} es capaz de tratar con imágenes. Para ello las matrices \alert{bidimensionales} o \alert{tridimensionales} son transformadas a un vector \alert{unidimensional} con la operación de \say{\alert{flatten}}.

\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{figures/Tema 3/Flatten.png}
\end{figure}
\end{frame}

\begin{frame}{Problemas del perceptrón}
El principal \alert{inconveniente} de esta aproximación es que se pierde toda la información \alert{espacial} de la imagen.

Esto hace que se pierdan las \alert{relaciones} de \alert{distancia} y \alert{color}.

Otro problema es la \alert{enorme} magnitud de las redes creadas de esta manera.

\centering
{\Large 512x512x3 píxeles = 786.432 neuronas entrada}
\end{frame}

\begin{frame}{Redes convolucionales}
Las redes neuronales \alert{convolucionales} surgen para adaptar las redes neuronales al \alert{tratamiento de imágenes}.

Los principales beneficios de su uso son los siguientes:
\begin{itemize}
    \item Aprovechamiento de la información \alert{espacial}.
    \item Reducción del número de \alert{parámetros}.
    \item \alert{Invarianza} aprendida de los datos.
\end{itemize}
\end{frame}

\section{Fundamentos de las redes convolucionales}

\begin{frame}{Operación de convolución}
La operación de \alert{convolución} consiste en la \alert{combinación lineal} de una ventana de píxeles de una imagen.

Para ello hay dos elementos fundamentales:
\begin{itemize}
    \item \alert{Imagen de entrada}: Una matriz \alert{bidimensional} de datos (normalmente normalizada a \alert{[-1, 1]} o \alert{[0, 1]}).
    \item \alert{Filtro o kernel}: Una matriz (normalmente de 3x3 o 5x5) con la que se realizará la \alert{combinación lineal} de los elementos de la imagen.
\end{itemize}

\begin{figure}
    \centering
    \includegraphics[width=0.5\textwidth]{figures/Tema 3/Convolucion2D_1.png}
\end{figure}
\end{frame}

\begin{frame}{Operación de convolución}
La salida se calcula  haciendo una \alert{combinación lineal} de cada región de la imagen. De esta manera la salida contiene la activación de cada zona de la imagen.

Esta región que el \alert{kernel} es capaz de \alert{observar} se conoce como \alert{campo receptivo}.

\begin{figure}
    \centering
    \includegraphics[width=0.7\textwidth]{figures/Tema 3/Convolucion2D_2.png}
\end{figure}
\end{frame}


\begin{frame}{Ejemplo de convolución 2-D}
\begin{figure}
    \centering
    \includegraphics[width=0.8\textwidth]{figures/Tema 2/Convolucion2D_2.png}
\end{figure}
\end{frame}

\begin{frame}{Ejemplo de convolución 2-D}
\begin{figure}
    \centering
    \includegraphics[width=0.8\textwidth]{figures/Tema 2/Convolucion2D_3.png}
\end{figure}
\end{frame}

\begin{frame}{Ejemplo de convolución 2-D}
\begin{figure}
    \centering
    \includegraphics[width=0.8\textwidth]{figures/Tema 2/Convolucion2D_4.png}
\end{figure}
\end{frame}

\begin{frame}{Ejemplo de convolución 2-D}
\begin{figure}
    \centering
    \includegraphics[width=0.8\textwidth]{figures/Tema 2/Convolucion2D_5.png}
\end{figure}
\end{frame}

\begin{frame}{Ejemplo de convolución 2-D}
\begin{figure}
    \centering
    \includegraphics[width=0.8\textwidth]{figures/Tema 2/Convolucion2D_Res.png}
\end{figure}
\end{frame}

\begin{frame}{Campo receptivo}
La salida de la \alert{operación} tiene como objetivo la \alert{extracción de características} de las distintas \alert{regiones de la imagen}.

El \alert{campo receptivo} de cada celda de la salida se \alert{activa} cuando detecta una \alert{estructura de interés}.

\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{figures/Tema 3/ReceptiveActivation.png}
\end{figure}
\end{frame}

\begin{frame}{Campo receptivo}
La salida de la \alert{operación} tiene como objetivo la \alert{extracción de características} de las distintas \alert{regiones de la imagen}.

El \alert{campo receptivo} de cada celda de la salida se \alert{activa} cuando detecta una \alert{estructura de interés}.

\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{figures/Tema 3/ReceptiveActivation_1.png}
\end{figure}
\end{frame}

\begin{frame}{De neuronas a convoluciones}
Una \alert{red de neuronas} convolucional sustituye las capas \alert{densas} por capas \alert{convolucionales}.

Cada capa convolucional está compuesta por una \alert{serie} de \alert{filtros} de igual tamaño. Estos filtros se encargan de realizar el procesamiento de la información.

\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{figures/Tema 3/CNN_Net.png}
\end{figure}
\end{frame}

\begin{frame}{De neuronas a convoluciones}
Cada \alert{filtro} de la red está compuesto por una serie de \alert{neuronas}. Estas, igual que con las redes \alert{tradicionales} tienen un \alert{peso} asociado. Este peso es el que regula cómo se realiza la \alert{convolución}.

\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{figures/Tema 3/ConvNeuron.png}
\end{figure}
\end{frame}

\begin{frame}{De neuronas a convoluciones}
Tras haber realizado la \alert{convolución} de unos datos de entrada, el resultado pasa por una \alert{activación} a través de una \alert{función no lineal}, tal y como sucede en las redes neuronales densas.

\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{figures/Tema 3/ConvActivation.png}
\end{figure}
\end{frame}

\begin{frame}{Construcción de una \gls{cnn}}
La estructura de \alert{embudo} típica de las redes neuronales \alert{clasificadoras} también se aplica a \gls{cnn}. Para ello el objetivo es \alert{reducir} la dimensión de la imagen hasta generar una salida.

\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{figures/Tema 3/CNNEmbudo.png}
\end{figure}
\end{frame}

\begin{frame}{Construcción de una \gls{cnn}}
Las primeras capas \alert{convolucionales} de la red se encargan de la \alert{extracción de características} de la imagen. Posteriormente un \alert{perceptrón} se encarga de \alert{clasificar} las características extraídas para generar la \alert{salida deseada}.

\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{figures/Tema 3/CNNPerceptron.png}
\end{figure}
\end{frame}

\begin{frame}{Padding en la convolución}
Para controlar las \alert{dimensiones de salida} de cada capa convolucional se aplica un \textit{\alert{padding}} a la imagen de entrada. Este consiste en un marco de \say{\alert{0}} que evita la reducción dimensional.

\begin{figure}
    \centering
    \includegraphics[width=0.4\textwidth]{figures/Tema 2/Padding.png}
\end{figure}
\end{frame}

\begin{frame}{Padding en la convolución}
Existen dos \alert{configuraciones} predominantes para la elección de padding en la librería \alert{keras}:
\begin{itemize}
    \item \textbf{\alert{Valid}}: No se aplica \alert{ningún} padding.
    \item \textbf{\alert{Same}}: Se aplica un padding que haga que la \alert{dimensión de salida} sea igual a la de \alert{entrada}.
    
    \vfill
    {\large \textbf{Ejemplo}: Para una imagen de 16x16 píxeles y un filtro de 3x3, el padding \say{same} sería de 1 píxel.}
\end{itemize}
\end{frame}

\begin{frame}{Resultado de una capa convolucional}
Cada \alert{capa convolucional} está formada por una serie de convoluciones. Las \alert{dimensiones de salida} de cada capa vienen dadas por:
\begin{itemize}
    \item \alert{Alto y ancho}: Dependen de las dimensiones de los \alert{datos recibidos} y el \alert{padding} utilizado.
    \item \alert{Profundidad}: Corresponde con el \alert{número de filtros} aplicados a los datos.
\end{itemize}
\end{frame}

\begin{frame}{Resultado de una capa convolucional}
\begin{figure}
    \centering
    \includegraphics[width=0.7\textwidth]{figures/Tema 3/ConvDimensions_1.png}
\end{figure}
\end{frame}

\begin{frame}{Resultado de una capa convolucional}
\begin{figure}
    \centering
    \includegraphics[width=0.7\textwidth]{figures/Tema 3/ConvDimensions_2.png}
\end{figure}
\end{frame}

\begin{frame}{Resultado de una capa convolucional}
\begin{figure}
    \centering
    \includegraphics[width=0.7\textwidth]{figures/Tema 3/ConvDimensions_3.png}
\end{figure}
\end{frame}

\begin{frame}{Resultado de una capa convolucional}
\begin{figure}
    \centering
    \includegraphics[width=0.7\textwidth]{figures/Tema 3/ConvDimensions_4.png}
\end{figure}
\end{frame}

\begin{frame}{Resultado de una capa convolucional}
\begin{figure}
    \centering
    \includegraphics[width=0.7\textwidth]{figures/Tema 3/ConvDimensions_5.png}
\end{figure}
\end{frame}

\begin{frame}{Reducción dimensional en redes convolucionales}
Para formar el \say{\alert{embudo}} de la red se utilizan distintos mecanismos para \alert{reducir las dimensiones} de la información de la red. En concreto los dos mecanismos predominantes son:
\begin{itemize}
    \item \alert{Capas de pooling}
    \begin{itemize}
        \item MaxPooling
        \item AveragePooling
    \end{itemize}
    \item \alert{Convoluciones de strides=(2,2)}
\end{itemize}
\end{frame}

\begin{frame}{Reducción dimensional con Pooling}
\alert{\Large MaxPooling 2D}
La capa de MaxPooling2D reduce la dimensión de un vector cogiendo el \alert{máximo} de la ventana definida.

\begin{figure}
    \centering
    \includegraphics[width=0.7\textwidth]{figures/Tema 3/MaxPooling_1.png}
\end{figure}
\end{frame}

\begin{frame}{Reducción dimensional con Pooling}
\alert{\Large MaxPooling 2D}
La capa de MaxPooling2D reduce la dimensión de un vector cogiendo el \alert{máximo} de la ventana definida.

\begin{figure}
    \centering
    \includegraphics[width=0.7\textwidth]{figures/Tema 3/MaxPooling_2.png}
\end{figure}
\end{frame}

\begin{frame}{Reducción dimensional con Pooling}
\alert{\Large MaxPooling 2D}
La capa de MaxPooling2D reduce la dimensión de un vector cogiendo el \alert{máximo} de la ventana definida.

\begin{figure}
    \centering
    \includegraphics[width=0.7\textwidth]{figures/Tema 3/MaxPooling_3.png}
\end{figure}
\end{frame}

\begin{frame}{Reducción dimensional con Pooling}
\alert{\Large MaxPooling 2D}
La capa de MaxPooling2D reduce la dimensión de un vector cogiendo el \alert{máximo} de la ventana definida.

\begin{figure}
    \centering
    \includegraphics[width=0.7\textwidth]{figures/Tema 3/MaxPooling_4.png}
\end{figure}
\end{frame}

\begin{frame}{Reducción dimensional con Pooling}
\alert{\Large MaxPooling 2D}
La capa de MaxPooling2D reduce la dimensión de un vector cogiendo el \alert{máximo} de la ventana definida.

\begin{figure}
    \centering
    \includegraphics[width=0.7\textwidth]{figures/Tema 3/MaxPooling_5.png}
\end{figure}
\end{frame}

\begin{frame}{Reducción dimensional con Pooling}
\alert{\Large MaxPooling 2D}
La capa de MaxPooling2D reduce la dimensión de un vector cogiendo el \alert{máximo} de la ventana definida.

\begin{figure}
    \centering
    \includegraphics[width=0.7\textwidth]{figures/Tema 3/MaxPooling_res.png}
\end{figure}
\textit{*cabe destacar que el máximo se encarga de preservar la característica más importante}
\end{frame}

\begin{frame}{Reducción dimensional con Pooling}
\alert{\Large AveragePooling 2D}
La capa de AveragePooling2D reduce la dimensión de un vector cogiendo el \alert{promedio} de la ventana definida.

\begin{figure}
    \centering
    \includegraphics[width=0.7\textwidth]{figures/Tema 3/AvgPooling_1.png}
\end{figure}
\end{frame}

\begin{frame}{Reducción dimensional con Pooling}
\alert{\Large AveragePooling 2D}
La capa de AveragePooling2D reduce la dimensión de un vector cogiendo el \alert{promedio} de la ventana definida.

\begin{figure}
    \centering
    \includegraphics[width=0.7\textwidth]{figures/Tema 3/AvgPooling_2.png}
\end{figure}
\end{frame}

\begin{frame}{Reducción dimensional con Pooling}
\alert{\Large AveragePooling 2D}
La capa de AveragePooling2D reduce la dimensión de un vector cogiendo el \alert{promedio} de la ventana definida.

\begin{figure}
    \centering
    \includegraphics[width=0.7\textwidth]{figures/Tema 3/AvgPooling_res.png}
\end{figure}
\end{frame}

\begin{frame}{Strides en la convolución}
Los \alert{\textit{strides}} o pasos de una convolución corresponden con el número de casillas que se desplaza \alert{horizontal} y \alert{verticalmente} el filtro al realizar la convolución.

\begin{figure}
    \centering
    \includegraphics[width=0.9\textwidth]{figures/Tema 2/Strides2x2_2.png}
\end{figure}
\end{frame}

\begin{frame}{Strides en la convolución}
Los \alert{\textit{strides}} o pasos de una convolución corresponden con el número de casillas que se desplaza \alert{horizontal} y \alert{verticalmente} el filtro al realizar la convolución.

\begin{figure}
    \centering
    \includegraphics[width=0.9\textwidth]{figures/Tema 2/Strides2x2_3.png}
\end{figure}
\end{frame}

\begin{frame}{Strides en la convolución}
Los \alert{\textit{strides}} o pasos de una convolución corresponden con el número de casillas que se desplaza \alert{horizontal} y \alert{verticalmente} el filtro al realizar la convolución.

\begin{figure}
    \centering
    \includegraphics[width=0.9\textwidth]{figures/Tema 2/Strides2x2_Res.png}
\end{figure}
\end{frame}

\section{Tuneo de \glspl{cnn}}

\begin{frame}{Hiperparámetros de una convolución 2D}
La capa \alert{Conv2D} de la libería \alert{keras} tiene una serie de \alert{hiperparámetros} que permiten su \alert{configuración}, dentro de los más importantes se encuentran:
\begin{itemize}
    \item \alert{filters}
    \item \alert{kernel\_size}
    \item \alert{strides}
    \item \alert{padding}
    \item \alert{activation}
\end{itemize}
\end{frame}

\begin{frame}{Los hiperparámetros en una red}
Uno de los mayores \alert{inconvenientes} a la hora de realizar entrenamientos con redes neuronales artificiales es su \alert{difícil configuración}. Debido a la cantidad inmensa de \alert{hiperparámetros} a escoger.

Sin embargo, existen una serie de \alert{prácticas comunes} a la hora de tratar con \glspl{cnn}.
\end{frame}

\begin{frame}{Tamaño de imagen y filtros}
A la hora de escoger el \alert{número de filtros} de cada capa convolucional este va \alert{ligado} al tamaño de la \alert{matriz de datos}.

A medida que la imagen de entrada va \alert{reduciendo} su tamaño, el número de filtros \alert{aumenta}. Con esto se pretende extraer más \alert{características de alto nivel} cada vez cubriendo zonas más amplias de la imagen original.

\begin{figure}
    \centering
    \includegraphics[width=0.7\textwidth]{figures/Tema 3/DimensionFilters.png}
\end{figure}
\end{frame}

\begin{frame}{Tamaño de imagen y filtros}
Al mismo tiempo, a medida que el \alert{número} de filtros de \alert{multiplica por 2} las \alert{dimensiones} de la matriz de datos se \alert{reducen a la mitad}.

El objetivo de este \alert{intercambio} es mantener la \alert{misma cantidad} de información, pero tratada por la red.

\begin{figure}
    \centering
    \includegraphics[width=0.7\textwidth]{figures/Tema 3/ResolutionFilter_1.png}
\end{figure}
\end{frame}

\begin{frame}{Otros hiperparámetros}
\alert{\Large kernel\_size}

El tamaño del kernel \alert{habitualmente} es de \alert{(3, 3)} o \alert{(5, 5)}, en caso de imágenes muy grandes puede llegar a \alert{(7, 7)}.

Para matrices de datos \alert{más grandes} se utilizan \alert{kernels más grandes}, en casos combinando kernels de \alert{(5, 5)} para las \alert{primeras capas} y posteriormente \alert{(3, 3)} para capas más \alert{profundas.}

\vfill
\alert{\Large strides}

El paso de la convolución se mantiene a \alert{(1, 1)} a no ser que se desee una \alert{reducción dimensional}.
\end{frame}

\begin{frame}{Otros hiperparámetros}
\alert{\Large padding}

El padding de una convolución suele ser \alert{same} para controlar las dimensiones de la matriz de datos, pero no es extraño encontrar casos con padding \alert{valid}.

\vfill
\alert{\Large activation}

Para las \alert{capas ocultas} se suele utilizar la función \alert{ReLU} o \alert{LeakyReLU}, para la capa de \alert{salida} la activación depende del \alert{problema concreto}.
\end{frame}

\begin{frame}{Notebook de ejemplo, dimensiones de convolución}
El siguiente notebook contiene un breve código para explorar las \alert{dimensiones de salida} de una capa convolucional.

\begin{figure}
    \centering
    \includegraphics[width=0.4\textwidth]{figures/GoogleColab.png}
\end{figure}
\begin{itemize}
    \centering
    \item 2.2\_2-DimensionesConv2D.ipynb
\end{itemize}
\end{frame}

\begin{frame}{Aprendizaje de una red convolucional}
A lo largo del tema se estudiarán distintas \alert{arquitecturas} construidas con capas convolucionales, pero cabe destacar que la \alert{estructura por capas} de estas redes consigue \alert{imitar} el procesamiento del \alert{cortex cerebral} del cerebro.

Las capas \alert{ocultas} de las redes convolucionales contienen una \alert{jerarquía} especializada en la tarea para la que se entrena.

Esto se traduce en que, la \alert{primeras} capas de la red se encargan de procesar información de \alert{bajo nivel}, como \alert{líneas} o \alert{curvas}; mientras que las \alert{últimas} capas se encargan de información de \alert{alto nivel}, como una cara o la silueta de un animal.
\end{frame}

\begin{frame}{Aprendizaje de una red convolucional}
\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{figures/Tema 3/Cortex.jpg}
    \caption{\cite{Cortex}}
\end{figure}
\end{frame}

\begin{frame}{Aprendizaje de una red convolucional}
\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{figures/Tema 3/ConvHierarchy.png}
    \caption{\cite{siddiqui2018automatic}}
\end{figure}
\end{frame}

\begin{frame}{Notebook de ejemplo, clasificador con redes convolucionales}
El siguiente notebook contiene un ejemplo de clasificador redes convolucionales.

\begin{figure}
    \centering
    \includegraphics[width=0.4\textwidth]{figures/GoogleColab.png}
\end{figure}
\begin{itemize}
    \centering
    \item 2.2\_3-CNNImagenes.ipynb
\end{itemize}
\end{frame}

# ¡GRACIAS!<!--_class: endpage-->
