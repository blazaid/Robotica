---
marp : true
title : Deep learning en visión
author :
  - Alberto Díaz Álvarez <alberto.diaz@upm.es>
  - Guillermo Iglesias Hernández <guillermo.iglesias@upm.es>
paginate : true
theme : etsisi
description : >
  El deep learning como herramienta para la visión por computador
keywords: >
  Robótica, Percepción, Visión
math: mathjax
---

<!-- _class: titlepage -->

# Deep learning en visión

## Robótica

### Guillermo Iglesias Hernández y Alberto Díaz Álvarez

#### Departamento de Sistemas Informáticos - Universidad Politécnica de Madrid

##### 5 de octubre de 2023

[![height:30](https://img.shields.io/badge/License-CC%20BY--NC--SA%204.0-informational.svg)](https://creativecommons.org/licenses/by-nc-sa/4.0/)

---

# Conceptos básicos de redes de neuronas<!-- _class: section -->

---

# Neurona biológica vs. artificial

Sistema matemático capaz de realizar predicciones a partir de datos de entrada

- Propuesta por McCulloch y Pitts en 1943
- Basada en _imitar_ el comportamiento de una neurona biológica
- Toma ciertos _estímulos_ de entrada, los procesa y genera una nueva salida

<div class="columns">
<div class="column">

## Neurona biológica

- Estímulos $\rightarrow$ _impulsos nerviosos_

<center>
<img src="https://upload.wikimedia.org/wikipedia/commons/4/44/Neuron3.png" alt="Ilustración de una neurona biológica" style="height:150">
<figcaption align="center">

**Fig.1** - Neurona biológica. Fuente: [Wikipedia](https://commons.wikimedia.org/wiki/File:Neuron3.png).

</figcaption>
</center>
</div>
<div class="column">

## Neurona artificial

- Estímulos $\rightarrow$ _cálculos matemáticos_

<center>
<img src="https://upload.wikimedia.org/wikipedia/commons/5/53/Artificial_Neuron.svg" alt="Diagrama de neurona artificial" style="height:150">
<figcaption align="center">

**Fig.2** - Neurona artificial. Fuente: [Wikipedia](https://commons.wikimedia.org/wiki/File:Artificial_Neuron.svg).

</figcaption>
</center>
</div>
</div>

---

# Neurona artificial

<center>
<img src="https://www.electronicshub.org/wp-content/uploads/2019/05/Artificial-Neural-Networks-ANN-Processing-Units.jpg" alt="Componentes de una neurona" style="height: 200px">
<figcaption align="center">

**Fig.3** - Neurona artificial. Fuente: [ElectronicsHub](https://www.electronicshub.org/artificial-neural-networks-ann/).

</figcaption>
</center>

Para ello, existen diversos _elementos_ dentro de una neurona artificial:

- **Entradas** ($x_i$): Los valores numéricos de entrada
- **Salida** ($y$): El valor de salida de la neurona
- **Pesos** ($w_i$): Parámetros capaces de cambiar, suponen el aprendizaje de la neurona
- **Bias** ($b$): Peso cuya entrada _siempre_ es $1$ y que desplaza la función de activación
- **Función de activación**: $a$: Participa en el cálculo de la salida de la neurona

---

# Inferencia o propagación

<center>
<img src="https://www.electronicshub.org/wp-content/uploads/2019/05/Artificial-Neural-Networks-ANN-Processing-Units.jpg" alt="Componentes de una neurona" style="height: 200px">
<figcaption align="center">

**Fig.3** - Neurona artificial. Fuente: [ElectronicsHub](https://www.electronicshub.org/artificial-neural-networks-ann/).

</figcaption>
</center>

Se encarga de procesar la _entrada_ y generar la _salida_ correspondiente

1. Cada entrada $x_i$ es multiplicada por el valor de su peso correspondiente $w_i$,
   - La entrada del <i>bias</i> siempre es $1$, y tiene su propio peso (denominado $w_0$ o $b$)
2. Todos los productos se suman (**entrada neta**),
3. La entrada neta pasa por la función de activación $a$ para generar la salida $\hat{y}$.

Cuando hay varias capas, **la salida de una capa es la entrada de la siguiente**

---

# Estructura de capas

Las redes de neuronas se suelen organizar por capas

- Éstas se componen de varias neuronas
- Cuando cada neurona de una capa se conecta con todas las de la siguiente, se denomina **capa densa** o **fully connected**
- Si la red posee sólo capas densas se denomina perceptrón multicapa (MLP)

<center>
<img src="https://www.dtreg.com/uploaded/pageimg/MLFNwithWeights.jpg" alt="Esquema de un perceptrón multicapa">
<figcaption align="center">

**Fig.4** - Esquema de un perceptrón multicapa. Fuente: [AILephant](https://ailephant.com/glossary/multilayer-perceptron/).

</figcaption>
</center>

---

# Funciones de activación

Las **funciones de activación** de cada neurona pueden variar; algunas de las más populares son:

<center>
<img src="https://www.researchgate.net/profile/Karen-Loaiza/publication/344331692/figure/fig8/AS:965939822616576@1607309408063/Artificial-neural-network-activation-functions-In-this-figure-the-most-common_W640.jpg" alt="Algunas funciones de activación">
<figcaption align="center">

**Fig.5** - Algunas funciones de activación. Fuente: [Deep learning for decision support in dermatology](https://www.researchgate.net/profile/Karen-Loaiza/publication/344331692_Deep_learning_for_decision_support_in_dermatology/links/5fcd9838a6fdcc697be87133/Deep-learning-for-decision-support-in-dermatology.pdf).

</figcaption>
</center>

---

# Función de error (pérdida o <i>loss</i>)

Se usa para calcular el error entre salida deseada y real

- Para un ejemplo: _coste_ (<i>coste</i>); para muchos: _pérdida_ (<i>loss</i>),

<div class="columns">
<div class="column">
<center>
<img src="https://vitalflux.com/wp-content/uploads/2020/10/Screenshot-2020-10-15-at-5.46.17-PM.png" alt="Entropía cruzada (clasificación)" style="height:300">
<figcaption align="center">

**Fig.6** - Entropía cruzada (clasificación). Fuente: [Analytics Yogi](https://vitalflux.com/cross-entropy-loss-explained-with-python-examples/).

</figcaption>
</center>
</div>
<div class="column">
<center>
<img src="https://www.statlect.com/images/loss-function.png" alt="Ejemplos de loss en regresión" style="height:300">
<figcaption align="center">

**Fig.7** - Ejemplos de <i>loss</i> en regresión. Fuente: [StatLect](https://www.statlect.com/glossary/loss-function).

</figcaption>
</center>
</div>
</div>

---

# Algoritmo de retropropagación (<i>backpropagation</i>)

Es el encargado de _adaptar_ la red de neuronas a su cometido específico

$$
\begin{equation}
    \bigtriangleup w_i = w_i - \alpha \cdot \delta_i
\end{equation}
$$

- $\delta_i$ es directamente proporcional al _loss_ en la última capa
- $\delta_i$ es directamente proporcional al error de la capa inmediatamente posterior
  - De ahí lo de retropropagación, el error se va propagando de la última a la primera capa
- Para calcular la dirección del error se usa el gradiente de la función de activación

---

# Entrenamiento

<div class="columns-third">
<div class="column">

Entrenamiento en un esquema de aprendizaje supervisado:

1. **Inferencia**: Se calcula la salida de la red para una entrada,
2. **Calculo del error**: Se comparan las salidas real y deseada,
3. **Retropropagación**: Se modifican los pesos según el error.

Esta operación se realiza iterativamente hasta que el error sea lo suficientemente bajo

- Cada iteración se denomina **época** o <i>epoch</i> y es una vuelta a todo el conjunto de entrenamiento
- A cada porción de datos de entrenamiento se le denomina **lote** o <i>batch</i>

</div>
<div class="column">

<center>
<img src="https://imgs.xkcd.com/comics/trained_a_neural_net.png" alt="Cómic de aprendizaje automático">
<figcaption align="center">

**Fig.8** - Neurona artificial. Fuente: [XKCD](https://xkcd.com/2173/).

</figcaption>
</center>

</div>

---

# Entrenamiento de redes neuronales

Durante la creación de modelos, se suelen usar tres conjuntos de datos:

- **Entrenamiento** (<i>training</i>): Usado para entrenar el modelo,
- **Validación** (<i>validation</i>): Usado para validar el modelo **durante el entrenamiento**,
  - Suele ser un subconjunto del conjunto de entrenamiento
- **Testeo** (<i>testing</i>): Usado para probar el modelo una vez entrenado.
  - Debe ser un conjunto de datos no visto por el modelo durante el entrenamiento

<center>
<img src="https://miro.medium.com/v2/1*Nv2NNALuokZEcV6hYEHdGA.png" alt="Representación de los conjuntos de entrenamiento, validación y test">
<figcaption align="center">

**Fig.9** - Representación de los conjuntos de entrenamiento, validación y test. Fuente: [Towards Data Science](https://towardsdatascience.com/train-validation-and-test-sets-72cb40cba9e7).

</figcaption>
</center>

---

# Compromiso sesgo-varianza

En inglés <i>bias-variance tradeoff</i>, es el equilibrio entre dos tipos de error:

- **Sesgo** (<i>bias</i>): Error por supuestos demasiado simples (<i>underfitting</i>)
- **Varianza** (<i>variance</i>): Error por excesiva sensibilidad a los datos (<i>overfitting</i>)

Modelos y complejidad:

- **Modelo simple**: Puede no capturar las relaciones subyacentes en los datos
- **Modelo complejo**: Puede sobreajustarse, capturando ruido y anomalías

Implicaciones:

- **Sobreajuste** (<i>overfitting</i>): Modelos muy complejos con alta varianza
- **Subajuste** (<i>underfitting</i>): Modelos muy simples con alto sesgo
- Objetivo: Equilibrio donde el modelo es lo _suficientemente flexible_ para capturar la verdadera relación, pero no tanto como para ser engañado por el ruido

---

# ¿Cómo detectar altos sesgo o varianza?

## Detección de un alto sesgo:

- **Indicador**: Error elevado en entrenamiento
- **Soluciones**: Aumentar complejidad, más épocas, revisar arquitectura y calidad de datos.

## Deteción de una alta varianza:

- **Indicador**: Gran diferencia entre errores de entrenamiento y validación
- **Soluciones**: Más datos, usar regularización (ej. dropout), disminuir complejidad, aumentado de datos

---

# Problemas del gradiente<!-- _class: section -->

---

# Recordando qué es el gradiente

Vector que indica la dirección y magnitud de máximo crecimiento de una función

- En redes neuronales nos dice **cómo actualizar los pesos para minimizar el error**
- Se obtiene al derivar la función de <i>loss</i> respecto a cada peso
  - Así sabemos cuánto cambiaría la función de pérdida si ajustáramos un peso específico

<center>
<img src="https://miro.medium.com/v2/resize:fit:720/1*vchQOUUW_RPVjkb4pQF-1A.gif" alt="Gradiente calculándose para varios pesos y su evolución a lo largo de 10 iteraciones" height="300px">
<figcaption align="center">

**Fig.10** - Gradiente calculándose para varios pesos y su evolución a lo largo de $10$ iteraciones. Fuente: [Towards AI](https://pub.towardsai.net/deep-learning-from-scratch-in-modern-c-gradient-descent-670bc5889112).

</figcaption>
</center>

---

# Problema del desvaniecimiento del gradiente

Ocurre cuando los **gradientes** de las capas más alejadas a la entrada **tienden a disminuir exponencialmente** a medida que se retropropagan a través de la red

- Provoca actualizaciones mínimas, más cuanto más cercanas a la entrada
- Aprendizaje lento o nulo: Las capas profundas no convergen (o sí, pero muy lento)
- Mayor cuanto más capas (multiplicación continua de valores pequeños)

La principal causa es la naturaleza de ciertas funciones de activación

<center>
<img src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6A3A_rt4YmumHusvTvVTxw.png" alt="P.ej. <i>sigmoid</i> o <i>tanh</i> comprimen un amplio rango de valores de entrada a un rango limitado, resultando en derivadas muy pequeñas" height="200px">
<figcaption align="center">

**Fig.11** - La sigmoide comprime muchos valores de entrada a un rango limitado. Fuente: [Towards Data Science](https://towardsdatascience.com/derivative-of-the-sigmoid-function-536880cf918e).

</figcaption>
</center>

---

# Problema de la Explosión del Gradiente

Ocurre cuando los **gradientes** se vuelven **excesivamente grandes**, causando actualizaciones de pesos desproporcionadas, haciendo que la red sea inestable

- Es el fenómeno opuesto al desvanecimiento del gradiente
- Actualizaciones inestables, red que oscila y no converje, o incluso que diverje a infinito
- Riesgo de Overfitting: La red puede adaptarse demasiado a particularidades del conjunto de entrenamiento.
- Valores NaN: Las actualizaciones excesivas pueden llevar a valores numéricos indeseados o no válidos en la red.

> A diferencia del desvanecimiento del gradiente, donde el aprendizaje se detiene, la explosión del gradiente puede hacer que la red aprenda patrones incorrectos o simplemente falle.

---

# Soluciones a los problemas del gradiente

Algunas soluciones son de diseño o de parametrización:

- **Funciones de activación**: Optar por funciones como ReLU o sus variantes (Leaky ReLU, Parametric ReLU) que no saturan en regiones extensas
- **Inicialización de pesos**: Utilizar técnicas como la inicialización He o Xavier/Glorot, que consideran el tamaño de las capas anteriores y siguientes.
- **Optimizadores Avanzados**: Como Adam, RMSprop o Adagrad, que ajustan dinámicamente las tasas de aprendizaje.

Otras son ya técnicas específicas de estos problemas

- **Gradient Clipping**: Establece un umbral para limitar el tamaño del gradiente
- **Batch Normalization**: Normaliza la activación de las neuronas dentro de una capa para mantenerlas en un rango deseado.

---

# Perceptrón multicapa para procesar imágenes<!-- _class: section -->

---

# ¿Cómo procesar imágenes?

Las imágenes son matrices, pero las redes neuronales trabajan con vectores

- Así que no nos queda otra que _aplanar_ la imagen en un vector unidimensional

<center>
<img src="https://miro.medium.com/v2/resize:fit:1100/format:webp/1*IWUxuBpqn2VuV-7Ubr01ng.png" alt="Proceso de aplanado de matriz a vector para servir de entrada a un perceptrón multicapa" height="300px">
<figcaption align="center">

**Fig.12** - La entrada al perceptrón debe ser pasada a vector antes de ser procesada. Fuente: [Towards Data Science](https://towardsdatascience.com/the-most-intuitive-and-easiest-guide-for-convolutional-neural-network-3607be47480).

</figcaption>
</center>

En `keras` existe la capa `Flatten` precisamente para realizar esta operación

---

# Implementando un perceptrón multicapa

<center>
<img src="https://upload.wikimedia.org/wikipedia/commons/d/d0/Google_Colaboratory_SVG_Logo.svg" alt="Logotipo de Google Colab" style="height:250px">
</center>

El siguiente notebook contiene un ejemplo de clasificador de imágenes usando un perceptrón multicapa como red neuronal

Ejercicio: [2.2. Clasificación de dígitos con un perceptrón multicapa.ipynb](https://githubtocolab.com/etsisi/Robotica/blob/main/Notebooks/2.2.%20Clasificación%20de%20dígitos%20con%20un%20perceptrón%20multicapa.ipynb)<sup>1</sup>

> <sup>1</sup> <https://githubtocolab.com/etsisi/Robotica/blob/main/Notebooks/2.2.%20Clasificación%20de%20dígitos%20con%20un%20perceptrón%20multicapa.ipynb>

---

# Problemas del perceptrón

Al transformar la matriz en vector **se pierde la información espacial** de la imagen

- En particular, todas las relaciones de _color_ y _distancia_

<center>
<img src="https://sds-platform-private.s3-us-east-2.amazonaws.com/uploads/73_blog_image_1.png" alt="Aplanar una imagen hace que perdamos su información espacial" height="250px">
<figcaption align="center">

**Fig.13** - Aplanar una imagen hace que perdamos su información espacial. Fuente: [SuperDataScience](https://www.superdatascience.com/blogs/convolutional-neural-networks-cnn-step-3-flattening).

</figcaption>
</center>

Y también está la **enorme magnitud de las redes** creadas de esta manera

- Ejemplo: Imagen de $512\times512$ píxeles $\rightarrow$ ¡$786.432$ neuronas de entrada!

---

# Fundamentos de las redes convolucionales<!-- _class: section -->

---

# Operación de convolución

Las redes **convolucionales** son redes adaptadas al **tratamiento de imágenes**

- Y se apoyan en la **convolución**, que es el producto punto entre dos matrices

<center>
<img src="https://miro.medium.com/v2/resize:fit:640/0*dSjXKGG6kJ5kVUgJ" alt="Operación de convolución aplicada a una imagen" height="250px">
<figcaption align="center">

**Fig.13** - Operación de convolución aplicada a una imagen. Fuente: [IceCream Labs](https://icecreamlabs.medium.com/3x3-convolution-filters-a-popular-choice-75ab1c8b4da8).

</figcaption>
</center>

Para ello deben existir dos elementos fundamentales:

- Imagen de entrada: Matriz tridimensional de datos
- Filtro o <i>kernel</i>: Matriz con la que realizar la operación de _convolución_

---


\begin{frame}{Redes convolucionales}

Los principales beneficios de su uso son los siguientes:
\begin{itemize}
    \item Aprovechamiento de la información \alert{espacial}.
    \item Reducción del número de \alert{parámetros}.
    \item \alert{Invarianza} aprendida de los datos.
\end{itemize}

---

# Campo receptivo

La salida de la convolución es una _extracción de características_ de la imagen

<center>
<img src="images/t2/receptive-field.png" alt="Extracción de características asociadas a un filtro concreto" height="300px">
<figcaption align="center">

**Fig.14** - Extracción de características asociadas a un filtro concreto.

</figcaption>
</center>

El **campo receptivo** de cada celda de salida se **activa** al detectar la **característica**

- Diferentes filtros detectarán diferentes características

---

# ¿Y qué aprende la red?

Una red de convolución sustituye las primeras capas **densas** por **convolucionales**

- El bloque convolucional extrae características
- El bloque denso predice de acuerdo a características, (y no a píxeles en bruto)

Cada capa convolucional está compuesta por una serie de filtros de igual tamaño

<center>
<img src="images/t2/conv-neuron.png" alt="Los pesos de las capas de convolución son los filtros" height="200px">
<figcaption align="center">

**Fig.15** - Los pesos de las capas de convolución son los filtros.

</figcaption>
</center>

La red aprenderá qué filtros extraen las características para el problema a resolver

---

# Tamaño de la salida de una capa convolucional

Supongamos que tenemos:

- Una imagen de entrada de $n \times m$ píxeles y $c$ canales,
- Un filtro de $f \times g$ píxeles,
- Una capa de convolución con $k$ filtros,

Entonces la salida de la capa convolucional será de:

$$
\begin{equation}
  (n - f + 1) \times (m - g + 1) \times k
\end{equation}
$$

La salida es una nueva imagen **más pequeña** de las características extraídas

---

# Padding en la convolución

Muchas convoluciones reducen el tamaño de la imagen de salida

- Lo que es un problema en redes muy profundas

¿Cómo se soluciona? Con un relleno de ceros (<i>padding</i>) en la imagen de entrada

- Filtro de $n \times m$ $\rightarrow$ $\lfloor n/2 \rfloor$ arriba y abajo, $\lfloor m/2 \rfloor$ derecha e izquierda

<center>
<img src="https://miro.medium.com/v2/resize:fit:720/1*O06nY1U7zoP4vE5AZEnxKA.gif" alt="Los pesos de las capas de convolución son los filtros" height="200px">
<figcaption align="center">

**Fig.16** - Los pesos de las capas de convolución son los filtros.

</figcaption>
</center>

Así la imagen de **salida** tendrá el **mismo tamaño** que la de **entrada**

---

# Salto (<i>stride</i>) en la operación de convolución

Un <i>stride</i> es el número de píxeles que se desplaza el filtro al realizar la convolución

- No tienen por qué coincidir ambos desplazamientos (y por defecto son $1$)

<hr>

<div class="columns">
<div class="column">

La fórmula de la dimensión cuando hay:

- Una **dimensión** de entrada de $n$ píxeles,
- Un **filtro** de $f$ píxeles,
- Un **salto** de $s$ píxeles,
- Un **padding** de $p$ píxeles

Es la siguiente:

$$
\frac{n - f + 2p}{s} + 1
$$

</div>
<div class="column">

<center>
<img src="https://miro.medium.com/v2/resize:fit:1100/1*awHl8cYgPSP4Aj8t929T5g.gif" alt="Filtro de 3 por 3 en una convolución con desplazamiento de 3 horizontal, 3 vertical" width="320">
<figcaption align="center">

**Fig.17** - Filtro de $3 \times 3$ con desplazamiento de $3$ en ambas direcciones. Fuente: [The Startup](https://medium.com/swlh/convolutional-neural-networks-part-2-padding-and-strided-convolutions-c63c25026eaa)
</figcaption>
</center>

</div>
</div>

---

# Reducción dimensional en redes convolucionales

La operación principal para ello es el <i>pooling</i>, cuyas dos variantes son:

- <i>MaxPooling</i>: Se queda con el valor máximo de la ventana
- <i>AveragePooling</i>: Se queda con el valor medio de la ventana

Es similar a una operación de convolución, pero sin pesos

<center>
<img src="https://media.licdn.com/dms/image/C4E12AQHslvjeX_AJww/article-inline_image-shrink_1000_1488/0/1596044084694?e=1701907200&v=beta&t=zkQYZV4oiLhtxcsgEm_vl1g_L6vohD3xqG_GHPOOLTw" alt="Ejemplo de operación de max pooling" height="200px">
<figcaption align="center">

**Fig.18** - Ejemplo de operación de <i>max pooling</i>. Autor: [Parva Shah](https://www.linkedin.com/pulse/do-we-really-need-pooling-layer-our-cnn-architecture-parva-shah).

</figcaption>
</center>

Normalmente el filtro y el salto (stride) son iguales, y suelen ser de $2 \times 2$

---

# Clasificador con redes convolucionales

<center>
<img src="https://upload.wikimedia.org/wikipedia/commons/d/d0/Google_Colaboratory_SVG_Logo.svg" alt="Logotipo de Google Colab" style="height:250px">
</center>

El siguiente notebook contiene un ejemplo de clasificador redes convolucionales como red neuronal

Ejercicio: [2.3. Entendiendo las redes de convolución.ipynb](https://githubtocolab.com/etsisi/Robotica/blob/main/Notebooks/2.3.%20Entendiendo%20las%20redes%20de%20convolución.ipynb)<sup>2</sup>

> <sup>2</sup> <https://githubtocolab.com/etsisi/Robotica/blob/main/Notebooks/2.3.%20Entendiendo%20las%20redes%20de%20convolución.ipynb>

---

# ¡GRACIAS!<!--_class: endpage-->
